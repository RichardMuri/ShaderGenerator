{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6864_hearthstone_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGKFhwVErhFR"
      },
      "source": [
        "# 6.864 ShaderGenerator Final Project\n",
        "\n",
        "This notebook contains code that trains the Hearthstone baseline model for the ShaderGenerator final project. We first download our Github repo that contains the datasets we use, install some dependencies, and set up our environment and imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7x4yYTIy4L-"
      },
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "rm -rf ShaderGenerator\n",
        "git clone \\\n",
        "    --depth 1 \\\n",
        "    --filter=blob:none \\\n",
        "    --no-checkout \\\n",
        "    https://github.com/RichardMuri/ShaderGenerator.git\n",
        "cd ShaderGenerator\n",
        "git checkout main -- torchASN/ card2code/third_party/hearthstone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4kYvhk-qxO6"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwkh6yNm2CSZ"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/ShaderGenerator/\")\n",
        "sys.path.append(\"/content/ShaderGenerator/torchASN/\")\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch import cuda\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from common.config import *\n",
        "from components.dataset import *\n",
        "\n",
        "from grammar.grammar import Grammar\n",
        "\n",
        "from grammar.python3.python3_transition_system import Python3TransitionSystem\n",
        "from models.ASN import ASNParser\n",
        "from models import nn_utils\n",
        "\n",
        "from torch import optim\n",
        "import os\n",
        "import time\n",
        "\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "device = None\n",
        "if cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "else:\n",
        "  print('WARNING: you are running this project on a cpu!')\n",
        "  device = 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjGgFYDSBlsT"
      },
      "source": [
        "# Pre-processing Hearthstone Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqWCLoMMBlsU"
      },
      "source": [
        "%%bash \n",
        "cd ShaderGenerator/\n",
        "export PYTHONPATH=\"${PYTHONPATH}:torchASN/\"\n",
        "python torchASN/datasets/hearthstone/make_dataset.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufdbe1PI0bxM"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "We now train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVztDoDz52ev"
      },
      "source": [
        "asdl_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/python_3_7_12_asdl.txt\"\n",
        "vocab = \"/content/ShaderGenerator/torchASN/data/hearthstone/vocab.bin\"\n",
        "train_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/train.bin\"\n",
        "dev_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/dev.bin\"\n",
        "dropout = 0.3\n",
        "enc_hid_size = 100\n",
        "src_emb_size = 100\n",
        "field_emb_size = 100\n",
        "max_epoch = 100\n",
        "clip_grad = 5.0\n",
        "batch_size = 32\n",
        "lr = 0.003\n",
        "model_file = f\"model.hearthstone.enc{enc_hid_size}.src{src_emb_size}.field{field_emb_size}.drop{dropout}.max_ep{max_epoch}.batch{batch_size}.lr{lr}.clip_grad{clip_grad}.bin\"\n",
        "save_to = f\"/content/ShaderGenerator/torchASN/checkpoints/hearthstone/{model_file}\"\n",
        "log_every = 50\n",
        "run_val_after = 5\n",
        "max_decode_step = 70\n",
        "max_naive_parse_depth = 18\n",
        "\n",
        "@dataclass\n",
        "class Arguments:\n",
        "    asdl_file: str\n",
        "    vocab: str\n",
        "    train_file: str\n",
        "    dev_file: str\n",
        "    dropout: float\n",
        "    enc_hid_size: int\n",
        "    src_emb_size: int\n",
        "    field_emb_size: int\n",
        "    max_epoch: int\n",
        "    clip_grad: float\n",
        "    batch_size: int\n",
        "    lr: float\n",
        "    model_file: str\n",
        "    save_to: str\n",
        "    log_every: int\n",
        "    run_val_after: int\n",
        "    max_decode_step: int\n",
        "    max_naive_parse_depth: int\n",
        "\n",
        "args = Arguments(asdl_file=asdl_file, vocab=vocab, train_file=train_file, dev_file=dev_file, dropout=dropout, enc_hid_size=enc_hid_size, src_emb_size=src_emb_size, \n",
        "                 field_emb_size=field_emb_size, max_epoch=max_epoch, clip_grad=clip_grad, batch_size=batch_size, lr=lr, model_file=model_file, save_to=save_to, log_every=log_every, \n",
        "                 run_val_after=run_val_after, max_decode_step=max_decode_step, max_naive_parse_depth=max_naive_parse_depth)\n",
        "\n",
        "\n",
        "train_set = Dataset.from_bin_file(args.train_file)\n",
        "if args.dev_file:\n",
        "    dev_set = Dataset.from_bin_file(args.dev_file)\n",
        "else:\n",
        "    dev_set = Dataset(examples=[])\n",
        "\n",
        "vocab = pickle.load(open(args.vocab, 'rb'))\n",
        "grammar = Grammar.from_text(open(args.asdl_file).read())\n",
        "# transition_system = Registrable.by_name(args.transition_system)(grammar)\n",
        "transition_system = Python3TransitionSystem(grammar)\n",
        "\n",
        "parser = ASNParser(args, transition_system, vocab)\n",
        "nn_utils.glorot_init(parser.parameters())\n",
        "\n",
        "optimizer = optim.Adam(parser.parameters(), lr=args.lr)\n",
        "best_acc = 0.0\n",
        "log_every = args.log_every\n",
        "\n",
        "train_begin = time.time()\n",
        "\n",
        "for epoch in tqdm(range(1, args.max_epoch + 1)):\n",
        "    train_iter = 0\n",
        "    loss_val = 0.\n",
        "    epoch_loss = 0.\n",
        "\n",
        "    parser.train()\n",
        "\n",
        "    epoch_begin = time.time()\n",
        "    for batch_example in train_set.batch_iter(batch_size=args.batch_size, shuffle=False):\n",
        "        optimizer.zero_grad()\n",
        "        loss = parser.score(batch_example)\n",
        "        loss_val += torch.sum(loss).data.item()\n",
        "        epoch_loss += torch.sum(loss).data.item()\n",
        "        loss = torch.mean(loss)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(parser.parameters(), args.clip_grad)\n",
        "\n",
        "        optimizer.step()\n",
        "        train_iter += 1\n",
        "        if train_iter % log_every == 0:\n",
        "            print(\"[epoch {}, step {}] loss: {:.3f}\".format(\n",
        "                epoch, train_iter, loss_val / (log_every * args.batch_size)))\n",
        "            loss_val = 0.\n",
        "\n",
        "    # print(epoch, 'Train loss', '{:.3f}'.format(epoch_loss / len(train_set)), 'time elapsed %d' % (time.time() - epoch_begin))\n",
        "    print('[epoch {}] train loss {:.3f}, epoch time {:.0f}, total time {:.0f}'.format(\n",
        "        epoch, epoch_loss / len(train_set), time.time() - epoch_begin, time.time() - train_begin))\n",
        "    if epoch > args.run_val_after:\n",
        "        eval_begin = time.time()\n",
        "        parser.eval()\n",
        "        with torch.no_grad():\n",
        "            parse_results = [parser.naive_parse(ex) for ex in dev_set]\n",
        "        match_results = [transition_system.compare_ast(r, e.tgt_ast) for r, e in zip(parse_results, dev_set)]\n",
        "        match_acc = sum(match_results) * 1. / len(match_results)\n",
        "        # print('Eval Acc', match_acc)\n",
        "        print('[epoch {}] eval acc {:.3f}, eval time {:.0f}'.format(\n",
        "            epoch, match_acc, time.time() - eval_begin))\n",
        "\n",
        "        if match_acc >= best_acc:\n",
        "            best_acc = match_acc\n",
        "            parser.save(args.save_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djLGvjOO7-n4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}