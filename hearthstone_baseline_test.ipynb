{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGKFhwVErhFR"
      },
      "source": [
        "# 6.864 ShaderGenerator Final Project\n",
        "\n",
        "This notebook contains code that trains the Hearthstone baseline model for the ShaderGenerator final project. We first download our Github repo that contains the datasets we use, install some dependencies, and set up our environment and imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7x4yYTIy4L-"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "rm -rf ShaderGenerator\n",
        "git clone \\\n",
        "    --depth 1 \\\n",
        "    --filter=blob:none \\\n",
        "    --no-checkout \\\n",
        "    https://github.com/RichardMuri/ShaderGenerator.git\n",
        "cd ShaderGenerator\n",
        "git checkout main -- torchASN/ card2code/third_party/hearthstone trained_models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4kYvhk-qxO6"
      },
      "outputs": [],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwkh6yNm2CSZ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/ShaderGenerator/\")\n",
        "sys.path.append(\"/content/ShaderGenerator/torchASN/\")\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch import cuda\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from common.config import *\n",
        "from components.dataset import *\n",
        "\n",
        "from grammar.grammar import Grammar\n",
        "\n",
        "from grammar.python3.python3_transition_system import Python3TransitionSystem\n",
        "from models.ASN import ASNParser\n",
        "from models import nn_utils\n",
        "\n",
        "from torch import optim\n",
        "import os\n",
        "import time\n",
        "\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "device = None\n",
        "if cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "else:\n",
        "  print('WARNING: you are running this project on a cpu!')\n",
        "  device = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjGgFYDSBlsT"
      },
      "source": [
        "# Pre-processing Hearthstone Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqWCLoMMBlsU"
      },
      "outputs": [],
      "source": [
        "%%bash \n",
        "cd ShaderGenerator/\n",
        "export PYTHONPATH=\"${PYTHONPATH}:torchASN/\"\n",
        "python torchASN/datasets/hearthstone/make_dataset.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufdbe1PI0bxM"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "We now train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVztDoDz52ev"
      },
      "outputs": [],
      "source": [
        "asdl_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/python_3_7_12_asdl.txt\"\n",
        "vocab = \"/content/ShaderGenerator/torchASN/data/hearthstone/vocab.bin\"\n",
        "train_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/train.bin\"\n",
        "dev_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/dev.bin\"\n",
        "test_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/test.bin\"\n",
        "dropout = 0.3\n",
        "enc_hid_size = 100\n",
        "src_emb_size = 100\n",
        "field_emb_size = 100\n",
        "max_epoch = 100\n",
        "clip_grad = 5.0\n",
        "batch_size = 32\n",
        "lr = 0.003\n",
        "model_file = f\"model.hearthstone.enc{enc_hid_size}.src{src_emb_size}.field{field_emb_size}.drop{dropout}.max_ep{max_epoch}.batch{batch_size}.lr{lr}.clip_grad{clip_grad}.bin\"\n",
        "save_to = f\"/content/ShaderGenerator/torchASN/checkpoints/hearthstone/{model_file}\"\n",
        "log_every = 50\n",
        "run_val_after = 5\n",
        "max_decode_step = 70\n",
        "max_naive_parse_depth = 18\n",
        "beam_size = 10\n",
        "\n",
        "@dataclass\n",
        "class Arguments:\n",
        "    asdl_file: str\n",
        "    vocab: str\n",
        "    train_file: str\n",
        "    dev_file: str\n",
        "    dropout: float\n",
        "    enc_hid_size: int\n",
        "    src_emb_size: int\n",
        "    field_emb_size: int\n",
        "    max_epoch: int\n",
        "    clip_grad: float\n",
        "    batch_size: int\n",
        "    lr: float\n",
        "    model_file: str\n",
        "    save_to: str\n",
        "    log_every: int\n",
        "    run_val_after: int\n",
        "    max_decode_step: int\n",
        "    max_naive_parse_depth: int\n",
        "\n",
        "args = Arguments(asdl_file=asdl_file, vocab=vocab, train_file=train_file, dev_file=dev_file, test_file=test_file, dropout=dropout, enc_hid_size=enc_hid_size, src_emb_size=src_emb_size,\n",
        "                 field_emb_size=field_emb_size, max_epoch=max_epoch, clip_grad=clip_grad, batch_size=batch_size, lr=lr, model_file=model_file, save_to=save_to, log_every=log_every,\n",
        "                 run_val_after=run_val_after, max_decode_step=max_decode_step, max_naive_parse_depth=max_naive_parse_depth, beam_size=beam_size)\n",
        "\n",
        "\n",
        "test_set = Dataset.from_bin_file(args.test_file)\n",
        "model_path = f\"/content/ShaderGenerator/trained_models/{model_file}\"\n",
        "parser = ASNParser.load(args.model_file, ex_args=args, cuda=True)\n",
        "\n",
        "parser.eval()\n",
        "with torch.no_grad():\n",
        "    parse_results = []\n",
        "    for ex in tqdm(test_set, desc='Decoding', file=sys.stdout, total=len(test_set)):\n",
        "        parse_results.append(parser.parse(ex) )\n",
        "# match_results = [ parser.transition_system.compare_ast(r, e.tgt_ast) for r, e in zip(parse_results, test_set)]\n",
        "# match_acc = sum(match_results) * 1. / len(match_results)\n",
        "# print(\"Eval Acc\", match_acc)bv\n",
        "act_tree_to_ast = lambda x: parser.transition_system.build_ast_from_actions(x)\n",
        "top_asts = [ act_tree_to_ast(x[0].action_tree) if x else None for x in parse_results]\n",
        "top_codes = [parser.transition_system.ast_to_surface_code(x) for x in top_asts]\n",
        "# match_results = [ parser.transition_system.compare_ast(r, e.tgt_ast) for r, e in zip(top_asts, test_set)]\n",
        "match_results = [ \" \".join(e.tgt_toks) == r for e, r in zip(test_set, top_codes)]\n",
        "# top_asts = [parser.transition_system]\n",
        "\n",
        "match_acc = sum(match_results) * 1. / len(match_results)\n",
        "# [print(\"%s\\n\\t==>%s\\n\\t==>%s\" % (\" \".join(e.src_toks), \" \".join(e.tgt_toks), c)) for e,c in zip(test_set, top_codes)]\n",
        "\n",
        "with open(\"output.txt\", \"w\") as f:\n",
        "    for c in top_codes:\n",
        "        f.write(c.replace(\" \",\"\") + \"\\n\")\n",
        "\n",
        "# oracle_res = []\n",
        "# i = 0\n",
        "# acc = 0\n",
        "# for e, c in zip(test_set, top_codes):\n",
        "#     gt_code = \" \".join(e.tgt_toks)\n",
        "#     pred_code = c\n",
        "#     eq_res = check_equiv(pred_code, gt_code)\n",
        "#     oracle_res.append(eq_res)\n",
        "#     acc += eq_res\n",
        "#     i += 1\n",
        "#     # print(acc, i)\n",
        "# print(\"String Acc\", match_acc)\n",
        "# print(\"DFA Acc\", sum(oracle_res) * 1.0/len(oracle_res) )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "6864_hearthstone_baseline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
