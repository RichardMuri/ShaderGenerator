{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6864_hearthstone_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGKFhwVErhFR"
      },
      "source": [
        "# 6.864 ShaderGenerator Final Project\n",
        "\n",
        "This notebook contains code that trains the Hearthstone baseline model for the ShaderGenerator final project. We first download our Github repo that contains the datasets we use, install some dependencies, and set up our environment and imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7x4yYTIy4L-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12929d0b-9a42-4296-ce31-955bf71dc542"
      },
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "rm -rf ShaderGenerator\n",
        "git clone \\\n",
        "    --depth 1 \\\n",
        "    --filter=blob:none \\\n",
        "    --no-checkout \\\n",
        "    https://github.com/RichardMuri/ShaderGenerator.git\n",
        "cd ShaderGenerator\n",
        "git checkout main -- torchASN/ card2code/third_party/hearthstone trained_models/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'ShaderGenerator'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4kYvhk-qxO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40abc45e-5812-43f3-ae3b-4bb2fc373ab3"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwkh6yNm2CSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfe1caa-fc10-4e42-c31c-7f14fda2c4e7"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/ShaderGenerator/\")\n",
        "sys.path.append(\"/content/ShaderGenerator/torchASN/\")\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch import cuda\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from common.config import *\n",
        "from components.dataset import *\n",
        "\n",
        "from grammar.grammar import Grammar\n",
        "\n",
        "from grammar.python3.python3_transition_system import Python3TransitionSystem\n",
        "from models.ASN import ASNParser\n",
        "from models import nn_utils\n",
        "\n",
        "from torch import optim\n",
        "import os\n",
        "import time\n",
        "from google.colab import files\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "device = None\n",
        "if cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "else:\n",
        "  print('WARNING: you are running this project on a cpu!')\n",
        "  device = 'cpu'\n",
        "# device = 'cpu'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: you are running this project on a cpu!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjGgFYDSBlsT"
      },
      "source": [
        "# Pre-processing Hearthstone Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqWCLoMMBlsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca916e2-23e5-4ca2-8c2e-4fa11e2ee974"
      },
      "source": [
        "# %%bash \n",
        "# cd ShaderGenerator/\n",
        "# export PYTHONPATH=\"${PYTHONPATH}:torchASN/\"\n",
        "# python torchASN/datasets/hearthstone/make_dataset.py"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"torchASN/datasets/hearthstone/make_dataset.py\", line 109, in <module>\n",
            "    make_dataset()\n",
            "  File \"torchASN/datasets/hearthstone/make_dataset.py\", line 95, in make_dataset\n",
            "    train_set = load_dataset(\"train\", transition_system)\n",
            "  File \"torchASN/datasets/hearthstone/make_dataset.py\", line 68, in load_dataset\n",
            "    assert transition_system.compare_ast(ast_from_action, tgt_ast)\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufdbe1PI0bxM"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "We now train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVztDoDz52ev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb4a0c3-8ac8-4652-fd31-d071e44bb076"
      },
      "source": [
        "asdl_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/python_3_7_12_asdl.txt\"\n",
        "vocab = \"/content/ShaderGenerator/torchASN/data/hearthstone/vocab.bin\"\n",
        "train_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/train.bin\"\n",
        "dev_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/dev.bin\"\n",
        "test_file = \"/content/ShaderGenerator/torchASN/data/hearthstone/test.bin\"\n",
        "dropout = 0.3\n",
        "enc_hid_size = 100\n",
        "src_emb_size = 100\n",
        "field_emb_size = 100\n",
        "max_epoch = 100\n",
        "clip_grad = 5.0\n",
        "batch_size = 32\n",
        "lr = 0.003\n",
        "model_file = f\"model.hearthstone.enc{enc_hid_size}.src{src_emb_size}.field{field_emb_size}.drop{dropout}.max_ep{max_epoch}.batch{batch_size}.lr{lr}.clip_grad{clip_grad}.bin\"\n",
        "save_to = f\"/content/ShaderGenerator/torchASN/checkpoints/hearthstone/{model_file}\"\n",
        "log_every = 50\n",
        "run_val_after = 5\n",
        "max_decode_step = 70\n",
        "max_naive_parse_depth = 18\n",
        "beam_size = 10\n",
        "\n",
        "@dataclass\n",
        "class Arguments:\n",
        "    asdl_file: str\n",
        "    vocab: str\n",
        "    train_file: str\n",
        "    dev_file: str\n",
        "    test_file: str\n",
        "    dropout: float\n",
        "    enc_hid_size: int\n",
        "    src_emb_size: int\n",
        "    field_emb_size: int\n",
        "    max_epoch: int\n",
        "    clip_grad: float\n",
        "    batch_size: int\n",
        "    lr: float\n",
        "    model_file: str\n",
        "    save_to: str\n",
        "    log_every: int\n",
        "    run_val_after: int\n",
        "    max_decode_step: int\n",
        "    max_naive_parse_depth: int\n",
        "    beam_size: int\n",
        "    device: str\n",
        "\n",
        "\n",
        "args = Arguments(asdl_file=asdl_file, vocab=vocab, train_file=train_file, dev_file=dev_file, test_file=test_file, dropout=dropout, enc_hid_size=enc_hid_size, src_emb_size=src_emb_size,\n",
        "                 field_emb_size=field_emb_size, max_epoch=max_epoch, clip_grad=clip_grad, batch_size=batch_size, lr=lr, model_file=model_file, save_to=save_to, log_every=log_every,\n",
        "                 run_val_after=run_val_after, max_decode_step=max_decode_step, max_naive_parse_depth=max_naive_parse_depth, beam_size=beam_size, device=device)\n",
        "\n",
        "\n",
        "\n",
        "# test_set = Dataset.from_bin_file(args.test_file)\n",
        "# model_path = f\"/content/drive/MyDrive/{model_file}\"\n",
        "model_path = \"/content/drive/MyDrive/model.hearthstone.bin\"\n",
        "\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "use_cuda = False\n",
        "if device == 'cuda':\n",
        "  use_cuda = True\n",
        "\n",
        "parser = ASNParser.load(model_path, ex_args=args, cuda=use_cuda)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1514GbLTTkS"
      },
      "source": [
        "# parser.eval()\n",
        "# with torch.no_grad():\n",
        "#     parse_results = []\n",
        "#     for ex in tqdm(test_set, desc='Decoding', file=sys.stdout, total=len(test_set)):\n",
        "#         parse_results.append(parser.parse(ex) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0uHzsM--Yli"
      },
      "source": [
        "with open(\"parse_results.txt\", \"wb\") as f:\n",
        "  pickle.dump(parse_results, f)\n",
        "\n",
        "files.download(\"parse_results.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4qx5ebqQiRi",
        "outputId": "e9eb4c14-a6c3-499e-afa3-66548c1e7b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "path = \"content/ShaderGenerator/trained_models/parse_results.txt\"\n",
        "with open(path, \"rb\") as f:\n",
        "  parse_results = pickle.load(f)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4c1af5000562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"content/ShaderGenerator/trained_models/parse_results.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mparse_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'content/ShaderGenerator/trained_models/parse_results.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71181YDeb0mJ",
        "outputId": "ffd19f83-8937-46dd-8a87-3a8765a5e5aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "# match_results = [ parser.transition_system.compare_ast(r, e.tgt_ast) for r, e in zip(parse_results, test_set)]\n",
        "# match_acc = sum(match_results) * 1. / len(match_results)\n",
        "# print(\"Eval Acc\", match_acc)bv\n",
        "act_tree_to_ast = lambda x: parser.transition_system.build_ast_from_actions(x)\n",
        "top_asts = [ act_tree_to_ast(x[0].action_tree) if x else None for x in parse_results]\n",
        "top_codes = [parser.transition_system.ast_to_surface_code(x) for x in top_asts if x is not None]\n",
        "# match_results = [ parser.transition_system.compare_ast(r, e.tgt_ast) for r, e in zip(top_asts, test_set)]\n",
        "match_results = [ \" \".join(e.tgt_toks) == r for e, r in zip(test_set, top_codes)]\n",
        "# top_asts = [parser.transition_system]\n",
        "\n",
        "match_acc = sum(match_results) * 1. / len(match_results)\n",
        "# [print(\"%s\\n\\t==>%s\\n\\t==>%s\" % (\" \".join(e.src_toks), \" \".join(e.tgt_toks), c)) for e,c in zip(test_set, top_codes)]\n",
        "\n",
        "\n",
        "with open(\"output.txt\", \"w\") as f:\n",
        "    for c in top_codes:\n",
        "        f.write(c.replace(\" \",\"\") + \"\\n\")\n",
        "\n",
        "files.download(\"output.txt\")\n",
        "\n",
        "with open(\"trees.txt\", \"w\") as f:\n",
        "  for tree in top_asts:\n",
        "    f.write(top_asts.to_string() + \"\\n\")\n",
        "\n",
        "files.download(\"trees.txt\")\n",
        "# oracle_res = []\n",
        "# i = 0\n",
        "# acc = 0\n",
        "# for e, c in zip(test_set, top_codes):\n",
        "#     gt_code = \" \".join(e.tgt_toks)\n",
        "#     pred_code = c\n",
        "#     eq_res = check_equiv(pred_code, gt_code)\n",
        "#     oracle_res.append(eq_res)\n",
        "#     acc += eq_res\n",
        "#     i += 1\n",
        "#     # print(acc, i)\n",
        "# print(\"String Acc\", match_acc)\n",
        "# print(\"DFA Acc\", sum(oracle_res) * 1.0/len(oracle_res) )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-17ce1b28473a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtop_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition_system\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mast_to_surface_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_asts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# match_results = [ parser.transition_system.compare_ast(r, e.tgt_ast) for r, e in zip(top_asts, test_set)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmatch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_toks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# top_asts = [parser.transition_system]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxvqzwhxVBM3",
        "outputId": "959be4d6-6be0-47e8-ec73-4d7b722539d1"
      },
      "source": [
        "%debug"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/content/ShaderGenerator/torchASN/grammar/python3/py_asdl_helper.py\u001b[0m(71)\u001b[0;36masdl_ast_to_python_ast\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     69 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0masdl_ast_to_python_ast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masdl_ast_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 71 \u001b[0;31m    \u001b[0mpy_node_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ast'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masdl_ast_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstructor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     72 \u001b[0;31m    \u001b[0mpy_ast_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_node_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     73 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u 12\n",
            "> \u001b[0;32m<ipython-input-13-5701029343bd>\u001b[0m(6)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m      4 \u001b[0;31m\u001b[0mact_tree_to_ast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition_system\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_ast_from_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      5 \u001b[0;31m\u001b[0mtop_asts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mact_tree_to_ast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparse_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m----> 6 \u001b[0;31m\u001b[0mtop_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition_system\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mast_to_surface_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_asts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0;31m# match_results = [ parser.transition_system.compare_ast(r, e.tgt_ast) for r, e in zip(top_asts, test_set)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      8 \u001b[0;31m\u001b[0mmatch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_toks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> top_asts.to_string()\n",
            "*** AttributeError: 'list' object has no attribute 'to_string'\n",
            "ipdb> top_asts[0].to_string()\n",
            "*** AttributeError: 'NoneType' object has no attribute 'to_string'\n",
            "ipdb> top_asts[1].to_string()\n",
            "*** AttributeError: 'NoneType' object has no attribute 'to_string'\n",
            "ipdb> len(top_asts)\n",
            "66\n",
            "ipdb> top_asts[2].to_string()\n",
            "*** AttributeError: 'NoneType' object has no attribute 'to_string'\n",
            "ipdb> top_asts[3]\n",
            "ipdb> print(top_asts)\n",
            "[None, None, None, None, None, None, None, None, None, None, None, None, mod -> Module(stmt* body), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, mod -> Module(stmt* body), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
            "ipdb> top_asts[12]\n",
            "mod -> Module(stmt* body)\n",
            "ipdb> top_asts[12].to_string()\n",
            "'(Module (stmt*-body))'\n",
            "ipdb> parser.transition_system.ast_to_surface_code(top_asts[12])\n",
            "''\n",
            "ipdb> q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/bdb.py\", line 357, in set_quit\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}